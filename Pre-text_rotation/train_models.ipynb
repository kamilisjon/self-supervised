{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa80770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c667b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"E:\\\\Datasets\\\\Br35H\\\\\"\n",
    "\n",
    "# define SSL model constants\n",
    "MODEL_SSL = \"model_v1.3.0\"\n",
    "DATASET_SSL = \"data_v1.3.0\"\n",
    "MAP_DICT = {'0': '2', '1': '4', '2': '6', '3': '8', '4': '10'}\n",
    "SAMPLE_DICT = {'0': [], '1': [], '2': [], '3': [], '4': []}\n",
    "\n",
    "# define constants for model fine-tuning\n",
    "MODEL_FINE_TUNE = \"model_v1.0.8\"\n",
    "DATASET_FINE_TUNE = \"data_v1.0.0\"\n",
    "\n",
    "IMG_SIZE = 128\n",
    "MINI_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9eddfd",
   "metadata": {},
   "source": [
    "## Load necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # Convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return int(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # Resize and norm the image\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ab7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model_SSL(class_count: int):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=None)\n",
    "    model.summary()\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization(name='batch_normalization')(x)\n",
    "    outputs = layers.Dense(class_count, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name='EfficientNetB0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd33cfb",
   "metadata": {},
   "source": [
    "## Visiaulize samples from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973024d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(os.path.join(DATA_ROOT, DATASET_SSL,'train'))\n",
    "\n",
    "rot_train_dataset = tf.data.Dataset.list_files(f\"{DATA_ROOT}\\\\{DATASET_SSL}\\\\train\\\\*\\\\*\", shuffle=False)\n",
    "rot_train_dataset = rot_train_dataset.shuffle(len(rot_train_dataset), reshuffle_each_iteration=False)\n",
    "rot_train_dataset = rot_train_dataset.map(process_path, num_parallel_calls=AUTOTUNE).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ea45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=iter(rot_train_dataset)\n",
    "\n",
    "for _ in range(500):\n",
    "    sample = next(iterator)\n",
    "    image = sample[0].numpy().reshape(IMG_SIZE,IMG_SIZE,3)\n",
    "    label = tf.math.argmax(sample[1], axis=1).numpy()[0]\n",
    "    SAMPLE_DICT[str(label)].append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12048022",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = len(SAMPLE_DICT)\n",
    "plt.figure(figsize=(12,10))\n",
    "i=1\n",
    "for row in range(class_count):\n",
    "    for column in range(5):\n",
    "        plt.subplot(class_count, 5, i)\n",
    "        image = SAMPLE_DICT[str(row)][column]\n",
    "        rot_angle = MAP_DICT[str(row)]\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'{rot_angle} degrees')\n",
    "        plt.axis('off')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e78f6",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(os.path.join(DATA_ROOT, DATASET_SSL, 'train'))\n",
    "\n",
    "rot_train_dataset = tf.data.Dataset.list_files(f\"{DATA_ROOT}\\\\{DATASET_SSL}\\\\train\\\\*\\\\*\", shuffle=False)\n",
    "rot_train_dataset = rot_train_dataset.shuffle(len(rot_train_dataset), reshuffle_each_iteration=False)\n",
    "rot_train_dataset = rot_train_dataset.map(process_path, num_parallel_calls=AUTOTUNE).batch(MINI_BATCH_SIZE)\n",
    "\n",
    "rot_val_dataset = tf.data.Dataset.list_files(f\"{DATA_ROOT}\\\\{DATASET_SSL}\\\\val\\\\*\\\\*\", shuffle=False)\n",
    "rot_val_dataset = rot_val_dataset.shuffle(len(rot_val_dataset), reshuffle_each_iteration=False)\n",
    "rot_val_dataset = rot_val_dataset.map(process_path, num_parallel_calls=AUTOTUNE).batch(MINI_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e05f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(os.path.join(DATA_ROOT, DATASET_FINE_TUNE, 'train'))\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files(f\"{DATA_ROOT}\\\\{DATASET_FINE_TUNE}\\\\train\\\\*\\\\*\", shuffle=False)\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset), reshuffle_each_iteration=False)\n",
    "train_dataset = train_dataset.map(process_path, num_parallel_calls=AUTOTUNE).batch(MINI_BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.list_files(f\"{DATA_ROOT}\\\\{DATASET_FINE_TUNE}\\\\val\\\\*\\\\*\", shuffle=False)\n",
    "val_dataset = val_dataset.shuffle(len(val_dataset), reshuffle_each_iteration=False)\n",
    "val_dataset = val_dataset.map(process_path, num_parallel_calls=AUTOTUNE).batch(MINI_BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.list_files(f\"{DATA_ROOT}\\\\{DATASET_FINE_TUNE}\\\\test\\\\*\\\\*\", shuffle=False)\n",
    "test_dataset = test_dataset.shuffle(len(test_dataset), reshuffle_each_iteration=False)\n",
    "test_dataset = test_dataset.map(process_path, num_parallel_calls=AUTOTUNE).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8bf31",
   "metadata": {},
   "source": [
    "## Initialize and train model for rotation angle classifiction pre-text task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"SSL_transfer_learning\",\n",
    "                 entity = 'ssl_bakalauras',\n",
    "                 name = MODEL_SSL,\n",
    "                 config={\n",
    "                     \"dataset_name\": DATASET_SSL,\n",
    "                     \"dataset_origin\": \"Br35H\",\n",
    "                     \"initial_weights\": \"Randomly initialized\",\n",
    "                     \"task\": \"pre_text - rotation angle classification\",\n",
    "                     \"pre_text_angles\": str(MAP_DICT),\n",
    "                     \"frozen_layers\": \"None\",\n",
    "                     \"loss_function\": \"categorical_crossentropy\",\n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"batch_size\": MINI_BATCH_SIZE,\n",
    "                     \"epochs\": 100,\n",
    "                     })\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# Initialize model\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model_SSL(class_count = 5)\n",
    "\n",
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=config.loss_function, metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a16c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(rot_train_dataset,\n",
    "          epochs=config.epochs,\n",
    "          validation_data=rot_val_dataset,\n",
    "          callbacks=[WandbCallback(save_model=(False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5adb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"C:\\\\Users\\\\Student\\\\Desktop\\\\Kamilio\\\\models\\\\{MODEL_SSL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7de835",
   "metadata": {},
   "source": [
    "## Fine-tune pretrained model for brain tumor classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beaf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"C:\\\\Users\\\\Student\\\\Desktop\\\\Kamilio\\\\models\\\\{MODEL_SSL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"SSL_transfer_learning\",\n",
    "                 entity = 'ssl_bakalauras',\n",
    "                 name = MODEL_FINE_TUNE,\n",
    "                 config={\n",
    "                     \"dataset_name\": DATASET_FINE_TUNE,\n",
    "                     \"dataset_origin\": \"Br35H\",\n",
    "                     \"initial_weights\": MODEL_SSL,\n",
    "                     \"task\": \"tumorous/non-tumorous brain classification\",\n",
    "                     \"frozen_layers\": \"All backbone layers\",\n",
    "                     \"loss_function\": \"categorical_crossentropy\",\n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"batch_size\": MINI_BATCH_SIZE,\n",
    "                     \"epochs\": 200,\n",
    "                     })\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# Initialize model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# Reinitializing dense classification layer\n",
    "inputs = model.input\n",
    "\n",
    "x = model.layers[-4].output\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "x = layers.BatchNormalization(name='batch_normalization')(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs, outputs, name=\"EfficientNetB0\")\n",
    "\n",
    "# Freezing the Convolutional Layers while keeping Dense layers as Trainable\n",
    "for layer in model2.layers:\n",
    "    if not (layer.name in ['pred', 'batch_normalization']):\n",
    "        layer.trainable=False\n",
    "    else:\n",
    "        layer.trainable=True\n",
    "\n",
    "# Compiling the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "model2.compile(optimizer=optimizer, loss=config.loss_function, metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82566333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model on Downstream Task\n",
    "model2.fit(train_dataset, validation_data=val_dataset, epochs=config.epochs, callbacks=[WandbCallback(save_model=(False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf06096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_auc = model2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e01df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"test_auc\": test_auc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772683be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.save(f\"C:\\\\Users\\\\Student\\\\Desktop\\\\Kamilio\\\\models\\\\{MODEL_FINE_TUNE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
